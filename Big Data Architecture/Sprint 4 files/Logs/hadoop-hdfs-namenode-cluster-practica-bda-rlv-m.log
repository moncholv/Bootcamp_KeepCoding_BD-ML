2019-02-02 02:52:24,712 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = cluster-practica-bda-rlv-m.europe-west4-c.c.bd-architecture-test.internal/10.164.0.27
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /etc/hadoop/conf:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/httpcore-4.4.4.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/gcs-connector-hadoop2-1.9.11.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/commons-lang3-3.4.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/snappy-java-1.0.5.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop/lib/httpclient-4.5.2.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/json-smart-1.3.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/hadoop-lzo-0.4.19.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/jetty-sslengine-6.1.26.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/.//hadoop-common-2.9.2-tests.jar:/usr/lib/hadoop/.//hadoop-common-2.9.2.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-auth-2.9.2.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-nfs-2.9.2.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-annotations-2.9.2.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.7.8.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.7.8.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.7.8.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-2.9.2-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-2.9.2.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.9.2.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.9.2.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.9.2-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-2.9.2-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-2.9.2.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-2.9.2.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-2.9.2-tests.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/httpcore-4.4.4.jar:/usr/lib/hadoop-yarn/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-lang3-3.4.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/paranamer-2.3.jar:/usr/lib/hadoop-yarn/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-net-3.1.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop-yarn/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/snappy-java-1.0.5.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/httpclient-4.5.2.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/gson-2.2.4.jar:/usr/lib/hadoop-yarn/lib/curator-client-2.7.1.jar:/usr/lib/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/json-smart-1.3.1.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.0.1.jar:/usr/lib/hadoop-yarn/lib/avro-1.7.7.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/lib/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/lib/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/lib/hadoop-yarn/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-yarn/lib/jsch-0.1.54.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jetty-sslengine-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.9.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-client-1.9.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.5.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.7.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-server-common-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//json-io-2.5.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//fst-2.50.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-common.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.4.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-server-resourcemanager-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-mapreduce/.//commons-lang3-3.4.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//jcip-annotations-1.0-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-bundle-1.11.199.jar:/usr/lib/hadoop-mapreduce/.//jersey-client-1.9.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-mapreduce/.//guice-3.0.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-registry-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-5.4.0.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//stax2-api-3.1.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.5.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-common-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-api.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//java-util-1.9.0.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.5.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-server-web-proxy-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//json-smart-1.3.1.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-mapreduce/.//guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//avro-1.7.7.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-0.8.0.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//javax.inject-1.jar:/usr/lib/hadoop-mapreduce/.//ehcache-3.3.1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.7.8.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//woodstox-core-5.0.3.jar:/usr/lib/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/.//jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/.//HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-mapreduce/.//json-20170516.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-api-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.7.8.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.7.8.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.54.jar:/usr/lib/hadoop-mapreduce/.//aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//jetty-sslengine-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.9.2.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.7.1.jar
STARTUP_MSG:   build = https://bigdataoss-internal.googlesource.com/third_party/apache/hadoop -r 807aa0cf99a816f6484a2304932688a51cd8a658; compiled by 'bigtop' on 2018-12-19T13:42Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2019-02-02 02:52:24,784 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-02 02:52:25,442 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-02 02:52:26,292 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-02 02:52:27,109 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-02 02:52:27,109 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-02 02:52:27,312 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://cluster-practica-bda-rlv-m
2019-02-02 02:52:28,589 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-02 02:52:28,674 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2019-02-02 02:52:29,134 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-02-02 02:52:29,302 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-02 02:52:29,670 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-02 02:52:29,709 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-02 02:52:29,726 INFO org.apache.hadoop.security.HttpCrossOriginFilterInitializer: CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2019-02-02 02:52:29,729 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-02 02:52:29,734 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-02 02:52:29,735 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-02 02:52:30,653 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-02 02:52:30,653 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-02 02:52:30,781 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-02 02:52:30,786 INFO org.mortbay.log: jetty-6.1.26
2019-02-02 02:52:32,913 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:9870
2019-02-02 02:52:33,080 WARN org.apache.hadoop.hdfs.server.common.Util: Path /hadoop/dfs/name should be specified as a URI in configuration files. Please update hdfs configuration.
2019-02-02 02:52:33,080 WARN org.apache.hadoop.hdfs.server.common.Util: Path /hadoop/dfs/name should be specified as a URI in configuration files. Please update hdfs configuration.
2019-02-02 02:52:33,087 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-02 02:52:33,087 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-02 02:52:33,138 WARN org.apache.hadoop.hdfs.server.common.Util: Path /hadoop/dfs/name should be specified as a URI in configuration files. Please update hdfs configuration.
2019-02-02 02:52:33,147 WARN org.apache.hadoop.hdfs.server.common.Util: Path /hadoop/dfs/name should be specified as a URI in configuration files. Please update hdfs configuration.
2019-02-02 02:52:33,494 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-02 02:52:33,600 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-02 02:52:33,613 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-02 02:52:33,614 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-02 02:52:33,663 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)
2019-02-02 02:52:33,664 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = hadoop
2019-02-02 02:52:33,664 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2019-02-02 02:52:33,676 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-02-02 02:52:33,911 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-02 02:52:34,020 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "cluster-practica-bda-rlv-w-0.europe-west4-c.c.bd-architecture-test.internal" to the list of included hosts from /etc/hadoop/conf/nodes_include
2019-02-02 02:52:34,034 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "cluster-practica-bda-rlv-w-1.europe-west4-c.c.bd-architecture-test.internal" to the list of included hosts from /etc/hadoop/conf/nodes_include
2019-02-02 02:52:34,034 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "cluster-practica-bda-rlv-w-2.europe-west4-c.c.bd-architecture-test.internal" to the list of included hosts from /etc/hadoop/conf/nodes_include
2019-02-02 02:52:34,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-02 02:52:34,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-02 02:52:34,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.retry-hostname-dns-lookup=true
2019-02-02 02:52:34,115 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-02 02:52:34,115 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 02 02:52:34
2019-02-02 02:52:34,127 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-02 02:52:34,127 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-02 02:52:34,139 INFO org.apache.hadoop.util.GSet: 2.0% max memory 1.4 GB = 29.6 MB
2019-02-02 02:52:34,147 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2019-02-02 02:52:34,307 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-02-02 02:52:34,342 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2019-02-02 02:52:34,372 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-02 02:52:34,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-02 02:52:34,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-02 02:52:34,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-02 02:52:34,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-02-02 02:52:34,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-02 02:52:34,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-02 02:52:34,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-02 02:52:34,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-02-02 02:52:34,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-02 02:52:34,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-02 02:52:34,389 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-02-02 02:52:34,641 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215
2019-02-02 02:52:35,017 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-02 02:52:35,025 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-02 02:52:35,025 INFO org.apache.hadoop.util.GSet: 1.0% max memory 1.4 GB = 14.8 MB
2019-02-02 02:52:35,026 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-02-02 02:52:35,028 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-02 02:52:35,028 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-02 02:52:35,028 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-02 02:52:35,061 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2019-02-02 02:52:35,113 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-02 02:52:35,116 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-02 02:52:35,117 INFO org.apache.hadoop.util.GSet: 0.25% max memory 1.4 GB = 3.7 MB
2019-02-02 02:52:35,117 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2019-02-02 02:52:35,147 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-02 02:52:35,150 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-02 02:52:35,151 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-02 02:52:35,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-02 02:52:35,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-02 02:52:35,215 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-02 02:52:35,215 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-02 02:52:35,233 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 1.4 GB = 454.5 KB
2019-02-02 02:52:35,233 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2019-02-02 02:52:35,315 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /hadoop/dfs/name/in_use.lock acquired by nodename 2777@cluster-practica-bda-rlv-m.europe-west4-c.c.bd-architecture-test.internal
2019-02-02 02:52:35,482 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /hadoop/dfs/name/current
2019-02-02 02:52:35,482 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-02-02 02:52:35,483 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/hadoop/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-02 02:52:35,821 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-02 02:52:35,992 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-02 02:52:36,009 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /hadoop/dfs/name/current/fsimage_0000000000000000000
2019-02-02 02:52:36,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2019-02-02 02:52:36,051 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2019-02-02 02:52:36,822 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-02 02:52:36,822 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1568 msecs
2019-02-02 02:52:38,707 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Service RPC server is binding to cluster-practica-bda-rlv-m:8051
2019-02-02 02:52:38,764 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 2000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-02 02:52:38,847 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8051
2019-02-02 02:52:39,292 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Setting ADDRESS cluster-practica-bda-rlv-m:8051
2019-02-02 02:52:39,296 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Lifeline RPC server is binding to cluster-practica-bda-rlv-m:8050
2019-02-02 02:52:39,297 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 400 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-02 02:52:39,312 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8050
2019-02-02 02:52:39,330 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Setting lifeline RPC address cluster-practica-bda-rlv-m/10.164.0.27:8050
2019-02-02 02:52:39,341 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to cluster-practica-bda-rlv-m:8020
2019-02-02 02:52:39,341 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 4000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-02 02:52:39,346 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-02 02:52:39,390 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use cluster-practica-bda-rlv-m:8020 to access this namenode/service.
2019-02-02 02:52:39,424 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2019-02-02 02:52:39,431 WARN org.apache.hadoop.hdfs.server.common.Util: Path /hadoop/dfs/name should be specified as a URI in configuration files. Please update hdfs configuration.
2019-02-02 02:52:39,512 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-02 02:52:39,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-02 02:52:39,597 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-02 02:52:39,597 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-02 02:52:39,597 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-02 02:52:39,673 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2019-02-02 02:52:39,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-02 02:52:39,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-02 02:52:39,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-02 02:52:39,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-02-02 02:52:39,682 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 84 msec
2019-02-02 02:52:39,729 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-02 02:52:39,734 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-02 02:52:39,809 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-02 02:52:39,811 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8051: starting
2019-02-02 02:52:39,818 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-02 02:52:39,819 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8050: starting
2019-02-02 02:52:39,821 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: cluster-practica-bda-rlv-m/10.164.0.27:8020
2019-02-02 02:52:39,821 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode service RPC up at: cluster-practica-bda-rlv-m/10.164.0.27:8051
2019-02-02 02:52:39,857 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-02 02:52:39,857 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-02 02:52:39,883 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 26 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2019-02-02 02:52:39,918 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-02 02:52:41,249 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.164.0.29:9866, datanodeUuid=843776e8-52bc-41ed-b3a9-7c0f6ee192d5, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-ef9cdbdc-53dd-4533-8308-f98ea6ecee26;nsid=1130148854;c=1549075936371) storage 843776e8-52bc-41ed-b3a9-7c0f6ee192d5
2019-02-02 02:52:41,252 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.164.0.29:9866
2019-02-02 02:52:41,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 843776e8-52bc-41ed-b3a9-7c0f6ee192d5 (10.164.0.29:9866).
2019-02-02 02:52:41,504 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3e31dd3a-04c3-4f9e-b56c-1e54f81052a5 for DN 10.164.0.29:9866
2019-02-02 02:52:41,623 INFO BlockStateChange: BLOCK* processReport 0x10df9fc92fea1000: Processing first storage report for DS-3e31dd3a-04c3-4f9e-b56c-1e54f81052a5 from datanode 843776e8-52bc-41ed-b3a9-7c0f6ee192d5
2019-02-02 02:52:41,637 INFO BlockStateChange: BLOCK* processReport 0x10df9fc92fea1000: from storage DS-3e31dd3a-04c3-4f9e-b56c-1e54f81052a5 node DatanodeRegistration(10.164.0.29:9866, datanodeUuid=843776e8-52bc-41ed-b3a9-7c0f6ee192d5, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-ef9cdbdc-53dd-4533-8308-f98ea6ecee26;nsid=1130148854;c=1549075936371), blocks: 0, hasStaleStorage: false, processing time: 6 msecs, invalidatedBlocks: 0
2019-02-02 02:52:42,476 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.164.0.28:9866, datanodeUuid=18980a30-bd82-42dc-b03a-c07290770c18, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-ef9cdbdc-53dd-4533-8308-f98ea6ecee26;nsid=1130148854;c=1549075936371) storage 18980a30-bd82-42dc-b03a-c07290770c18
2019-02-02 02:52:42,476 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.164.0.28:9866
2019-02-02 02:52:42,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 18980a30-bd82-42dc-b03a-c07290770c18 (10.164.0.28:9866).
2019-02-02 02:52:42,581 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c14d7cf8-bd4a-4481-9816-f4e4cbf927aa for DN 10.164.0.28:9866
2019-02-02 02:52:42,644 INFO BlockStateChange: BLOCK* processReport 0x3a5159a26fe41e97: Processing first storage report for DS-c14d7cf8-bd4a-4481-9816-f4e4cbf927aa from datanode 18980a30-bd82-42dc-b03a-c07290770c18
2019-02-02 02:52:42,644 INFO BlockStateChange: BLOCK* processReport 0x3a5159a26fe41e97: from storage DS-c14d7cf8-bd4a-4481-9816-f4e4cbf927aa node DatanodeRegistration(10.164.0.28:9866, datanodeUuid=18980a30-bd82-42dc-b03a-c07290770c18, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-ef9cdbdc-53dd-4533-8308-f98ea6ecee26;nsid=1130148854;c=1549075936371), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-02 02:52:43,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.164.0.30:9866, datanodeUuid=a9bb7c8f-0706-4977-a511-b1fa6334eb06, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-ef9cdbdc-53dd-4533-8308-f98ea6ecee26;nsid=1130148854;c=1549075936371) storage a9bb7c8f-0706-4977-a511-b1fa6334eb06
2019-02-02 02:52:43,407 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.164.0.30:9866
2019-02-02 02:52:43,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN a9bb7c8f-0706-4977-a511-b1fa6334eb06 (10.164.0.30:9866).
2019-02-02 02:52:43,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-d4630234-bb62-43ee-8861-4d90f1b90b12 for DN 10.164.0.30:9866
2019-02-02 02:52:43,564 INFO BlockStateChange: BLOCK* processReport 0xbf4e412144e9f9ad: Processing first storage report for DS-d4630234-bb62-43ee-8861-4d90f1b90b12 from datanode a9bb7c8f-0706-4977-a511-b1fa6334eb06
2019-02-02 02:52:43,564 INFO BlockStateChange: BLOCK* processReport 0xbf4e412144e9f9ad: from storage DS-d4630234-bb62-43ee-8861-4d90f1b90b12 node DatanodeRegistration(10.164.0.30:9866, datanodeUuid=a9bb7c8f-0706-4977-a511-b1fa6334eb06, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-ef9cdbdc-53dd-4533-8308-f98ea6ecee26;nsid=1130148854;c=1549075936371), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-02 02:53:05,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=10.164.0.29:9866, 10.164.0.28:9866 for /hadoop/tmp/mapred/history/recoverystore/HistoryServerState/tokens/keys/tmp-key_1
2019-02-02 02:53:06,195 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hadoop/tmp/mapred/history/recoverystore/HistoryServerState/tokens/keys/tmp-key_1
2019-02-02 02:53:06,603 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hadoop/tmp/mapred/history/recoverystore/HistoryServerState/tokens/keys/tmp-key_1 is closed by DFSClient_NONMAPREDUCE_-514054056_1
2019-02-02 02:53:06,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=10.164.0.28:9866, 10.164.0.30:9866 for /hadoop/tmp/mapred/history/recoverystore/HistoryServerState/tokens/keys/tmp-key_2
2019-02-02 02:53:06,828 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hadoop/tmp/mapred/history/recoverystore/HistoryServerState/tokens/keys/tmp-key_2 is closed by DFSClient_NONMAPREDUCE_-514054056_1
2019-02-02 02:53:19,044 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "cluster-practica-bda-rlv-w-0.europe-west4-c.c.bd-architecture-test.internal" to the list of included hosts from /etc/hadoop/conf/nodes_include
2019-02-02 02:53:19,045 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "cluster-practica-bda-rlv-w-1.europe-west4-c.c.bd-architecture-test.internal" to the list of included hosts from /etc/hadoop/conf/nodes_include
2019-02-02 02:53:19,045 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "cluster-practica-bda-rlv-w-2.europe-west4-c.c.bd-architecture-test.internal" to the list of included hosts from /etc/hadoop/conf/nodes_include
2019-02-02 02:53:19,567 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.0e96677b-8d16-427e-8eee-9152e70beede is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:53:29,967 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.e8bc5031-6369-486e-8e37-78fb8171ba51 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:53:39,978 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1067 Total time for transactions(ms): 100 Number of transactions batched in Syncs: 10 Number of syncs: 1057 SyncTimes(ms): 1265 
2019-02-02 02:53:39,985 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.bdc73b1f-d4a8-4da3-ac14-5db7ce3a207a is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:53:48,288 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:53:48 UTC 2019
2019-02-02 02:53:50,007 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.75943c03-a39b-41ed-b056-4125ecdeab18 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:54:00,029 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.7f0f29d9-9136-4ad3-8b45-c4a60bc5372b is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:54:10,047 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.145eb1ed-789f-43a1-944f-ef3481d41db5 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:54:18,123 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:54:18 UTC 2019
2019-02-02 02:54:20,069 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.313e2201-8a0f-4e60-831b-06a1273b24f5 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:54:30,092 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.d1334d4f-d3f9-42ee-b180-28fee86c1e94 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:54:40,113 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1085 Total time for transactions(ms): 102 Number of transactions batched in Syncs: 10 Number of syncs: 1075 SyncTimes(ms): 1286 
2019-02-02 02:54:40,117 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.8f31eee6-ee9c-4417-acfc-ddd641b6f73b is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:54:48,137 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:54:48 UTC 2019
2019-02-02 02:54:50,141 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.a1336c74-dbf2-4f61-a6f9-a433b383c851 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:55:00,166 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.57d3f93c-f663-40a0-be83-d5134932ac68 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:55:10,191 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.b3d1324a-e4b5-4741-bae3-4438dab1c1e3 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:55:18,114 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:55:18 UTC 2019
2019-02-02 02:55:20,219 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.a43b583e-8897-4982-b9a7-da291eb2f14e is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:55:30,253 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.0a4b7cbd-1f1a-430c-bd08-3cc0df8183ff is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:55:40,271 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1103 Total time for transactions(ms): 106 Number of transactions batched in Syncs: 10 Number of syncs: 1093 SyncTimes(ms): 1306 
2019-02-02 02:55:40,275 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.8b7ef327-71ff-44af-baa0-e87ac6e05e48 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:55:48,138 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:55:48 UTC 2019
2019-02-02 02:55:50,299 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.ec8b02ca-90b9-4cdf-9ad7-4240c47cda93 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:56:00,321 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.c8faa2fa-b57d-4fc3-9773-981f57e0c8f9 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:56:10,342 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.53ed93cf-ec45-40ab-a72a-d6cc902d47f4 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:56:18,097 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:56:18 UTC 2019
2019-02-02 02:56:20,363 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.af0cc250-6905-4192-999e-6b1bf473ae60 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:56:30,386 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.baa1f68a-e8e7-4fbe-aa96-5b4f19af86f1 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:56:40,399 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1121 Total time for transactions(ms): 108 Number of transactions batched in Syncs: 10 Number of syncs: 1111 SyncTimes(ms): 1323 
2019-02-02 02:56:40,404 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.bce77230-db36-49de-b3e0-017a74fad9d6 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:56:48,137 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:56:48 UTC 2019
2019-02-02 02:56:50,424 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.71f015a5-595d-4c74-91ec-08e40d1cfa8f is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:57:00,446 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.c3cb9bfa-7c6a-4c49-af1b-284bb642d302 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:57:10,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.d2474a41-ec78-4267-94b0-8589f27bb511 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:57:18,116 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:57:18 UTC 2019
2019-02-02 02:57:20,492 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.e762ca10-b9fb-423d-97cb-9846ef76b503 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:57:30,516 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.3b78f2f5-044e-44d8-8411-09bddfc58dd6 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:57:40,529 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1139 Total time for transactions(ms): 110 Number of transactions batched in Syncs: 10 Number of syncs: 1129 SyncTimes(ms): 1350 
2019-02-02 02:57:40,533 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.10477bd9-bfa1-4d04-b5a6-2dda33e968f6 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:57:48,128 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:57:48 UTC 2019
2019-02-02 02:57:50,551 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.c85345c1-70bf-4eff-a3e1-75fa53b270eb is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:58:00,570 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.0a739762-9c8f-4991-a9c5-e5895c183649 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:58:10,586 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.2e39bb3c-9a36-43bc-8692-acc35aa17b7e is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:58:18,113 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:58:18 UTC 2019
2019-02-02 02:58:20,613 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.683440e8-28f7-4646-bcd5-2250ddbcd46d is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:58:30,632 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.27565115-03ad-4f9a-a68a-be0afa3f859d is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:58:40,647 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1157 Total time for transactions(ms): 113 Number of transactions batched in Syncs: 10 Number of syncs: 1147 SyncTimes(ms): 1370 
2019-02-02 02:58:40,653 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.66a9f947-a11b-4a8a-b27d-da9d326a2ba3 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:58:48,106 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:58:48 UTC 2019
2019-02-02 02:58:50,669 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.8bb27d61-31a7-49d9-ba03-1adb4e212988 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:59:00,693 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.4d0ff0d0-92b0-4e33-9ad0-dafde7c5782d is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:59:10,709 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.11c51f36-b03e-4f68-bc3e-c4088c0317f5 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:59:18,106 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:59:18 UTC 2019
2019-02-02 02:59:20,729 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.39bcf0b3-d64d-47ac-959e-55657ed8d8b6 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:59:30,747 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.4795b564-8c3b-4aae-9c37-7047858fc163 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:59:40,764 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1175 Total time for transactions(ms): 115 Number of transactions batched in Syncs: 10 Number of syncs: 1165 SyncTimes(ms): 1389 
2019-02-02 02:59:40,768 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.2375ad83-83e9-4908-92a7-5c7960e8be36 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 02:59:48,108 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 02:59:48 UTC 2019
2019-02-02 02:59:50,790 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.18c6b9ae-76a1-474d-befb-552a835a979e is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:00:00,806 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.4a33c207-6dfb-442c-ac18-ed30d3b774a1 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:00:10,834 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.de2beb7b-5b64-4182-bff7-8263a12cf7fd is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:00:18,110 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:00:18 UTC 2019
2019-02-02 03:00:20,862 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.a2f83fc5-832a-4a7b-828d-f79fa5ae9f33 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:00:30,885 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.0b55ff4b-0585-4762-85bc-de7a15db0726 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:00:40,902 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1193 Total time for transactions(ms): 117 Number of transactions batched in Syncs: 10 Number of syncs: 1183 SyncTimes(ms): 1415 
2019-02-02 03:00:40,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.abb0ea7a-8bca-48c1-9b8c-7e195f68adc4 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:00:48,124 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:00:48 UTC 2019
2019-02-02 03:00:50,921 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.7ebae76d-02a9-42d4-a2ed-11989702defc is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:01:00,935 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.e8152d3d-6fd0-44aa-9b38-fc3ff8ef95c5 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:01:10,955 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.b01849ac-8a27-49ef-8949-78e0f70f4bf2 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:01:18,102 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:01:18 UTC 2019
2019-02-02 03:01:20,971 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.53a37100-f93f-4c60-b7fc-efbf851bbc2b is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:01:31,008 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.04b67753-14d1-4688-8b86-05cd60b82dfe is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:01:41,022 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1211 Total time for transactions(ms): 119 Number of transactions batched in Syncs: 10 Number of syncs: 1201 SyncTimes(ms): 1449 
2019-02-02 03:01:41,026 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.780ccb4d-3c86-4bfd-8008-3bc66a0d6daf is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:01:48,129 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:01:48 UTC 2019
2019-02-02 03:01:51,052 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.e7d38a87-639c-4a9b-97ac-d2751a54e3a4 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:02:01,069 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.8007ddbc-05e8-401b-bb36-863e9d32011d is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:02:11,088 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.29812a8f-28dd-4c2f-a014-bb2f7c309158 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:02:18,141 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:02:18 UTC 2019
2019-02-02 03:02:21,110 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.a314c8a8-52aa-46d2-a392-21379a2e24e1 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:02:25,828 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=10.164.0.29:9866, 10.164.0.28:9866 for /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job.jar
2019-02-02 03:02:25,962 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job.jar is closed by DFSClient_NONMAPREDUCE_272237288_1
2019-02-02 03:02:25,974 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 2 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job.jar
2019-02-02 03:02:26,157 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 2 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job.split
2019-02-02 03:02:26,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=10.164.0.30:9866, 10.164.0.29:9866, 10.164.0.28:9866 for /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job.split
2019-02-02 03:02:26,261 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job.split is closed by DFSClient_NONMAPREDUCE_272237288_1
2019-02-02 03:02:26,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=10.164.0.28:9866, 10.164.0.29:9866 for /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job.splitmetainfo
2019-02-02 03:02:26,300 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_272237288_1
2019-02-02 03:02:26,554 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=10.164.0.30:9866, 10.164.0.28:9866 for /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job.xml
2019-02-02 03:02:26,625 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job.xml is closed by DFSClient_NONMAPREDUCE_272237288_1
2019-02-02 03:02:31,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.02992c40-0dbb-4d97-b4e5-937e03ebc33c is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:02:36,050 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=10.164.0.29:9866, 10.164.0.30:9866 for /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job_1549075941254_0007_1_conf.xml
2019-02-02 03:02:36,136 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job_1549075941254_0007_1_conf.xml is closed by DFSClient_NONMAPREDUCE_116187745_1
2019-02-02 03:02:41,141 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1267 Total time for transactions(ms): 121 Number of transactions batched in Syncs: 20 Number of syncs: 1247 SyncTimes(ms): 1505 
2019-02-02 03:02:41,144 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.34870ec8-bcf7-4a08-afaa-12182167ba15 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:02:45,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=10.164.0.29:9866, 10.164.0.28:9866 for /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job_1549075941254_0007_1.jhist
2019-02-02 03:02:45,393 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job_1549075941254_0007_1.jhist for DFSClient_NONMAPREDUCE_116187745_1
2019-02-02 03:02:48,136 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:02:48 UTC 2019
2019-02-02 03:02:51,167 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.2d82831e-54d6-4435-8d36-0a580bf1c79c is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:03:01,183 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.21faf4bd-eb29-4058-b068-5e8daffc154c is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:03:02,122 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1537546778_1
2019-02-02 03:03:03,139 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1537546778_1
2019-02-02 03:03:03,168 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1549075941254_0007/job_1549075941254_0007_1.jhist is closed by DFSClient_NONMAPREDUCE_116187745_1
2019-02-02 03:03:03,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=10.164.0.29:9866, 10.164.0.28:9866 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1549075941254_0007.summary_tmp
2019-02-02 03:03:03,196 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1549075941254_0007.summary_tmp is closed by DFSClient_NONMAPREDUCE_116187745_1
2019-02-02 03:03:03,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=10.164.0.29:9866, 10.164.0.28:9866 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1549075941254_0007-1549076546942-root-word+count-1549076583141-1-8-SUCCEEDED-default-1549076555633.jhist_tmp
2019-02-02 03:03:03,295 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1549075941254_0007-1549076546942-root-word+count-1549076583141-1-8-SUCCEEDED-default-1549076555633.jhist_tmp is closed by DFSClient_NONMAPREDUCE_116187745_1
2019-02-02 03:03:03,319 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=10.164.0.29:9866, 10.164.0.28:9866 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1549075941254_0007_conf.xml_tmp
2019-02-02 03:03:03,340 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1549075941254_0007_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_116187745_1
2019-02-02 03:03:11,204 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.c8896c32-f085-407d-9812-e8c3cea26d88 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:03:18,133 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:03:18 UTC 2019
2019-02-02 03:03:21,224 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.43766071-3bb0-4b0c-85d6-f6cd9bfe36b2 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:03:31,239 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.93270d9d-88a1-4114-8d11-04d229b6656f is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:03:41,251 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1316 Total time for transactions(ms): 124 Number of transactions batched in Syncs: 26 Number of syncs: 1290 SyncTimes(ms): 1556 
2019-02-02 03:03:41,256 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.ae6fb569-1f63-4a91-8eb9-3220976617d2 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:03:48,117 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:03:48 UTC 2019
2019-02-02 03:03:51,279 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.2df243e1-e0b7-441d-a507-58a3639bee7a is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:04:01,295 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.22ed4b85-37e4-416d-9890-bd024772792d is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:04:11,312 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.460839dd-94e8-4f84-9a29-099e18813654 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:04:18,113 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:04:18 UTC 2019
2019-02-02 03:04:21,325 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.02d30e2a-219d-42a7-81a5-50bddde1054e is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:04:31,340 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.1c50ac06-3c17-45cb-a19b-9eccd5a5dec9 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:04:41,361 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1334 Total time for transactions(ms): 124 Number of transactions batched in Syncs: 26 Number of syncs: 1308 SyncTimes(ms): 1578 
2019-02-02 03:04:41,365 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.419b9a54-545a-4e07-abd7-1e49d5fc8642 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:04:48,115 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:04:48 UTC 2019
2019-02-02 03:04:51,379 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.914a520e-b41c-4be4-8a14-4ff90074e6e7 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:05:01,393 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.ac1aaa01-f0d5-49d5-a6f9-c148d996ecde is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:05:11,414 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.f0300527-1e13-4d82-8b7f-5d2ae3c45533 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:05:18,107 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:05:18 UTC 2019
2019-02-02 03:05:21,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.1cbaa29e-074e-41b9-acc5-edfd67f6893b is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:05:31,463 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.3364c299-c47d-43b2-911c-77dab81e2ed0 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:05:41,479 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1359 Total time for transactions(ms): 127 Number of transactions batched in Syncs: 29 Number of syncs: 1330 SyncTimes(ms): 1609 
2019-02-02 03:05:41,484 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.f4ff8279-5caa-4be9-9061-2472a62dd339 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:05:48,120 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:05:48 UTC 2019
2019-02-02 03:05:51,505 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.64980b4e-3f16-40e7-8c05-40d317eeec7b is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:06:01,525 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.4ef2a67e-5d4a-4cb7-a028-931b40cfd01d is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:06:11,541 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.1f07743d-96a4-4ff3-81ca-f7be4871d1c2 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:06:18,124 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:06:18 UTC 2019
2019-02-02 03:06:21,558 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.e5a04916-b5d5-4540-a975-f818363ef107 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:06:31,578 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.38017411-afa9-4a79-a09c-633ccef0e084 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:06:41,594 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1377 Total time for transactions(ms): 132 Number of transactions batched in Syncs: 29 Number of syncs: 1348 SyncTimes(ms): 1628 
2019-02-02 03:06:41,596 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.6d97accd-dfa4-45a3-8eb3-cc59769a7b7d is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:06:48,110 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:06:48 UTC 2019
2019-02-02 03:06:51,617 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.86bc9d88-2785-4bbc-a497-1093db5e2442 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:07:01,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.07e4cb01-f2ab-4c50-afe9-82ae6f99a13d is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:07:11,662 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.b021ea7c-8012-495f-8e0b-e91a6fea799d is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:07:18,118 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:07:18 UTC 2019
2019-02-02 03:07:21,678 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.80f9efce-31f5-41c9-9997-1286f3fbc723 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:07:31,696 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.38a47a0c-0131-4252-9a95-de4a4dbed2be is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:07:41,710 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1395 Total time for transactions(ms): 133 Number of transactions batched in Syncs: 29 Number of syncs: 1366 SyncTimes(ms): 1650 
2019-02-02 03:07:41,714 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.3f20a483-3a9a-4b01-9dc6-2c925585c7dd is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:07:48,113 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:07:48 UTC 2019
2019-02-02 03:07:51,735 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.1005ecbd-f8bd-4114-a406-43858009a98e is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:08:01,751 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.d700a46d-2ddd-44ec-a30a-e963fefea92f is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:08:11,768 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.cbdb6216-9f55-4748-8b9c-af03a5e9c0a8 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:08:18,114 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:08:18 UTC 2019
2019-02-02 03:08:21,782 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.5c34bd55-7faf-489f-848b-0e6ea76e94e5 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:08:31,796 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.1702eb8e-0fb4-4a90-baae-9805b3eafe4a is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:08:33,693 INFO logs: Aliases are enabled
2019-02-02 03:08:41,811 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1413 Total time for transactions(ms): 133 Number of transactions batched in Syncs: 29 Number of syncs: 1384 SyncTimes(ms): 1670 
2019-02-02 03:08:41,815 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/spark/eventlog/.2b925d0e-dee2-48f7-9a8d-b9ba310bd200 is closed by DFSClient_NONMAPREDUCE_-703051246_1
2019-02-02 03:08:48,118 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by root (auth:SIMPLE) from /10.164.0.27 for path / at Sat Feb 02 03:08:48 UTC 2019
